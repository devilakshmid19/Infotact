# üéôÔ∏è Speech Emotion Recognition

This project implements a **Speech Emotion Recognition (SER)** system using **Convolutional Neural Networks (CNNs)** and **MFCC feature extraction**. The model classifies speech into different emotions like happy, sad, angry, etc.

## üöÄ Features
- Extracts **Mel-frequency cepstral coefficients (MFCCs)** from speech.
- Uses **CNNs** for emotion classification.
- **Real-time audio** analysis support.
- **Noise filtering** for better accuracy.
- Supports **multiple datasets** for training.

## üìÇ Dataset
The dataset consists of speech samples labeled with different emotions. Common datasets include:
- **RAVDESS** (Ryerson Audio-Visual Database of Emotional Speech and Song)
- **TESS** (Toronto Emotional Speech Set)
- **CREMA-D** (Crowd-Sourced Emotional Multimodal Actors Dataset)
- **SAVEE** (Surrey Audio-Visual Expressed Emotion)

## üîß Installation

1. Clone this repository:
   ```sh
   git clone https://github.com/devilakshmid19/Speech-Emotion-Recognition.git
   cd Speech-Emotion-Recognition
